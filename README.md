# ollm

A simple demo providing series of LLM's API.

## Todo

- [ ] Reset cookies while `Error: bing explicit error: value: Throttled; message: Request is throttled.`
- [ ] Auto refresh bing cookies
- [x] Rebuild API
- [ ] Simple input/output

## Usage

Start the service and send the request: 

```shell
curl 'http://127.0.0.1:8080/v1/chat/completions' \
--header 'Content-Type: application/json' \
--data '{
    "model": "Creative",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "è®²ä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯"
      }
    ]
  }'
```

then you will receive the data in the following format:

```json
{
    "id": "chatcmpl-123",
    "object": "chat.completion",
    "created": 1711986244,
    "model": "Creative",
    "system_fingerprint": "fp_44709d6fcb",
    "choices": [
        {
            "index": 0,
            "message": {
                "content": "å½“ç„¶å¯ä»¥ï¼è¿™é‡Œæœ‰ä¸€ä¸ªï¼š\n\nä¸€ä¸ªç¨‹åºå‘˜çš„å¦»å­å¯¹ä»–è¯´ï¼šâ€œå»å•†åº—ä¹°ä¸€æ¡é¢åŒ…ï¼Œå¦‚æœæœ‰é¸¡è›‹ï¼Œä¹°å…­ä¸ªã€‚â€\nä»–å›æ¥äº†ï¼Œå¸¦ç€å…­æ¡é¢åŒ…ã€‚\nä»–çš„å¦»å­é—®ï¼šâ€œä¸ºä»€ä¹ˆä¹°äº†è¿™ä¹ˆå¤šé¢åŒ…ï¼Ÿâ€\nä»–å›ç­”ï¼šâ€œå› ä¸ºä»–ä»¬æœ‰é¸¡è›‹ã€‚â€ ğŸ˜„\n\nå¸Œæœ›è¿™ä¸ªç¬‘è¯èƒ½è®©ä½ ç¬‘ä¸€ç¬‘ï¼å¦‚æœä½ æƒ³å¬æ›´å¤šç¬‘è¯æˆ–è€…éœ€è¦å…¶ä»–å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n",
                "role": "assistant"
            },
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 1024,
        "completion_tokens": 1024,
        "total_tokens": 2048
    }
}
```

Supported Models:
- `Creative`
- `Balanced`
- `Precise`
- `gpt-3.5-turbo`
- `kimi`
- `gemini-pro`

## Thanks

This demo reference juzeon's open source project ([SydneyQt](https://github.com/juzeon/SydneyQt)), many thanks!ğŸ™